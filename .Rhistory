}
#Note: Replace below with your credentials following above reference
api_key <- "pkzfNBUsT7uFI5YEg2qhTT7b2"
api_secret <- "iEx2v9QtqT4zfY58JPzGFugrP3XzjjKwbdsW1J3NVoMTWvTYLK"
access_token <- "3914872158-vYvnOj6VE5ZpXcexVAu3YcMPh54uVdtfu4LLGVk"
access_token_secret <- "jhC9VDAZNbFj4mpPoWbRU3eq1KCrghMqIeiMpkCylcG8i"
#Note: This will ask us permission for direct authentication, type '1' for yes:
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
#Note: Replace below with your credentials following above reference
api_key <- "oJ6CmPerh7jHxP5ZHazRuez1U"
api_secret <- "zVKRrtlXKdWBPsFKaBs4h6z9cS0nQrZwoRI6dmhfDcdV3qDS20"
access_token <- "3914872158-vYvnOj6VE5ZpXcexVAu3YcMPh54uVdtfu4LLGVk"
access_token_secret <- "jhC9VDAZNbFj4mpPoWbRU3eq1KCrghMqIeiMpkCylcG8i"
#Note: This will ask us permission for direct authentication, type '1' for yes:
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
library(openssl)
library(httpuv)
#Note: This will ask us permission for direct authentication, type '1' for yes:
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
options(httr_oauth_cache = TRUE)
#Note: Replace below with your credentials following above reference
api_key <- "oJ6CmPerh7jHxP5ZHazRuez1U"
api_secret <- "zVKRrtlXKdWBPsFKaBs4h6z9cS0nQrZwoRI6dmhfDcdV3qDS20"
access_token <- "3914872158-vYvnOj6VE5ZpXcexVAu3YcMPh54uVdtfu4LLGVk"
access_token_secret <- "jhC9VDAZNbFj4mpPoWbRU3eq1KCrghMqIeiMpkCylcG8i"
#Note: This will ask us permission for direct authentication, type '1' for yes:
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
origop <- options("httr_oauth_cache")
options(httr_oauth_cache = TRUE)
packages <- c("twitteR", "openssl")
### checking if packages are already installed and installing if not
for(i in packages){
if(!(i %in% installed.packages()[, "Package"])){
install.packages(i)
}
library(i, character.only = TRUE) ## load packages
}
install.packages("base64enc")
require(base64enc)
#Note: Replace below with your credentials following above reference
api_key <- "oJ6CmPerh7jHxP5ZHazRuez1U"
api_secret <- "zVKRrtlXKdWBPsFKaBs4h6z9cS0nQrZwoRI6dmhfDcdV3qDS20"
access_token <- "3914872158-vYvnOj6VE5ZpXcexVAu3YcMPh54uVdtfu4LLGVk"
access_token_secret <- "jhC9VDAZNbFj4mpPoWbRU3eq1KCrghMqIeiMpkCylcG8i"
#Note: This will ask us permission for direct authentication, type '1' for yes:
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
#Note: This will ask us permission for direct authentication, type '1' for yes:
setup_twitter_oauth(api_key,api_secret)
#Note: Replace below with your credentials following above reference
api_key <- "oJ6CmPerh7jHxP5ZHazRuez1U"
api_secret <- "zVKRrtlXKdWBPsFKaBs4h6z9cS0nQrZwoRI6dmhfDcdV3qDS20"
access_token <- "3914872158-vYvnOj6VE5ZpXcexVAu3YcMPh54uVdtfu4LLGVk"
access_token_secret <- "jhC9VDAZNbFj4mpPoWbRU3eq1KCrghMqIeiMpkCylcG8i"
#Note: This will ask us permission for direct authentication, type '1' for yes:
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
library("openssl")
library("httpuv")
library("twitteR")
#Note: Replace below with your credentials following above reference
api_key <- "oJ6CmPerh7jHxP5ZHazRuez1U"
api_secret <- "zVKRrtlXKdWBPsFKaBs4h6z9cS0nQrZwoRI6dmhfDcdV3qDS20"
access_token <- "3914872158-vYvnOj6VE5ZpXcexVAu3YcMPh54uVdtfu4LLGVk"
access_token_secret <- "jhC9VDAZNbFj4mpPoWbRU3eq1KCrghMqIeiMpkCylcG8i"
#Note: This will ask us permission for direct authentication, type '1' for yes:
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
library(twitteR)
setup_twitter_oauth(api_key, api_secret, access_token=access_token,
access_secret=access_token_secret)
twitteR:::setup_twitter_oauth(api_key, api_secret, access_token=access_token,
access_secret=access_token_secret)
sessionInfo()
librarian::shelf(tidyverse, reshape2, readxl, data.table, nleqslv, BB, Metrics, ggthemes, pracma,
twitteR, ROAuth, hms, lubridate, tidytext, tm, wordcloud, igraph, glue, networkD3,
rtweet, stringr, ggeasy, plotly, janeaustenr, widyr)
if (!requireNamespace("httpuv", quietly = TRUE)) {
install.packages("httpuv")
}
library(openssl)
library(httpuv)
#Note: Replace below with your credentials following above reference
api_key <- "oJ6CmPerh7jHxP5ZHazRuez1U"
api_secret <- "zVKRrtlXKdWBPsFKaBs4h6z9cS0nQrZwoRI6dmhfDcdV3qDS20"
access_token <- "3914872158-vYvnOj6VE5ZpXcexVAu3YcMPh54uVdtfu4LLGVk"
access_token_secret <- "jhC9VDAZNbFj4mpPoWbRU3eq1KCrghMqIeiMpkCylcG8i"
#Note: This will ask us permission for direct authentication, type '1' for yes:
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
librarian::shelf(tidyverse, reshape2, readxl, data.table, nleqslv, BB, Metrics, ggthemes, pracma,
twitteR, ROAuth, hms, lubridate, tidytext, tm, wordcloud, igraph, glue, networkD3,
rtweet, stringr, ggeasy, plotly, janeaustenr, widyr)
library(openssl)
library(httpuv)
#Note: Replace below with your credentials following above reference
api_key <- "oJ6CmPerh7jHxP5ZHazRuez1U"
api_secret <- "zVKRrtlXKdWBPsFKaBs4h6z9cS0nQrZwoRI6dmhfDcdV3qDS20"
access_token <- "3914872158-vYvnOj6VE5ZpXcexVAu3YcMPh54uVdtfu4LLGVk"
access_token_secret <- "jhC9VDAZNbFj4mpPoWbRU3eq1KCrghMqIeiMpkCylcG8i"
#Note: This will ask us permission for direct authentication, type '1' for yes:
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
library(rtweet)
#Note: Replace below with your credentials following above reference
api_key <- "oJ6CmPerh7jHxP5ZHazRuez1U"
api_secret <- "zVKRrtlXKdWBPsFKaBs4h6z9cS0nQrZwoRI6dmhfDcdV3qDS20"
access_token <- "3914872158-vYvnOj6VE5ZpXcexVAu3YcMPh54uVdtfu4LLGVk"
access_token_secret <- "jhC9VDAZNbFj4mpPoWbRU3eq1KCrghMqIeiMpkCylcG8i"
#Note: This will ask us permission for direct authentication, type '1' for yes:
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
#Note: Replace below with your credentials following above reference
api_key <- "oJ6CmPerh7jHxP5ZHazRuez1U"
api_secret_key <- "zVKRrtlXKdWBPsFKaBs4h6z9cS0nQrZwoRI6dmhfDcdV3qDS20"
access_token <- "3914872158-vYvnOj6VE5ZpXcexVAu3YcMPh54uVdtfu4LLGVk"
access_token_secret <- "jhC9VDAZNbFj4mpPoWbRU3eq1KCrghMqIeiMpkCylcG8i"
#Note: This will ask us permission for direct authentication, type '1' for yes:
# setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
library(rtweet)
## authenticate via web browser
token <- create_token(
app = "RangoUnchained",
consumer_key = api_key,
consumer_secret = api_secret_key,
access_token = access_token,
access_secret = access_token_secret)
tweets <- searchTwitter("#globalwarming", n=4000, lang="en")
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
token
tweets <- searchTwitter("#globalwarming", n=4000, lang="en")
search_term <- '#ChristmasEveEve'
by <- 'hour'
tweets <- search_tweets(
search_term, n = 10000, retryonratelimit = TRUE
)
tweets
search_tweets(
search_term, n = 10000, retryonratelimit = TRUE
)
search_term <- '#War'
by <- 'hour'
tweets <- search_tweets(
search_term, n = 10000, retryonratelimit = TRUE
)
create_token(
app = "RangoUnchained",
consumer_key = api_key,
consumer_secret = api_secret_key,
access_token = access_token,
access_secret = access_token_secret)
search_term <- '#War'
by <- 'hour'
tweets <- search_tweets(
search_term, n = 10000, retryonratelimit = TRUE
)
tweetsSubSet <- tweets %>% select(created_at, text, hashtags)
librarian::shelf(tidyverse, reshape2, readxl, data.table, nleqslv, BB, Metrics, ggthemes, pracma,
twitteR, ROAuth, hms, lubridate, tidytext, tm, wordcloud, igraph, glue, networkD3,
rtweet, stringr, ggeasy, plotly, janeaustenr, widyr, textdata)
ggplot(output, aes(x=Sentiment,y=Count))+
geom_bar(stat = "identity", aes(fill = Sentiment))+
ggtitle("Barplot of Sentiment for inflation")
analysisSentiment
library(openssl)
library(httpuv)
library(rtweet)
token
tweets
#Note: Replace below with your credentials following above reference
api_key <- "oJ6CmPerh7jHxP5ZHazRuez1U"
api_secret_key <- "zVKRrtlXKdWBPsFKaBs4h6z9cS0nQrZwoRI6dmhfDcdV3qDS20"
access_token <- "3914872158-vYvnOj6VE5ZpXcexVAu3YcMPh54uVdtfu4LLGVk"
access_token_secret <- "jhC9VDAZNbFj4mpPoWbRU3eq1KCrghMqIeiMpkCylcG8i"
#Note: This will ask us permission for direct authentication, type '1' for yes:
# setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
library(rtweet)
## authenticate via web browser
token <- create_token(
app = "RangoUnchained",
consumer_key = api_key,
consumer_secret = api_secret_key,
access_token = access_token,
access_secret = access_token_secret)
## pre-processing text: This function is to clean the text of the tweet of
## any symbols, and other unnecessary items that are non-readable
cleanText <- function(x){
# convert to lower case
x = tolower(x)
# remove rt
x = gsub("rt", "", x)
# remove at
x = gsub("@\\w+", "", x)
# remove punctuation
x = gsub("[[:punct:]]", "", x)
# remove numbers
x = gsub("[[:digit:]]", "", x)
# remove links http
x = gsub("http\\w+", "", x)
# remove tabs
x = gsub("[ |\t]{2,}", "", x)
# remove blank spaces at the beginning
x = gsub("^ ", "", x)
# remove blank spaces at the end
x = gsub(" $", "", x)
# some other cleaning text
x = gsub('https://','',x)
x = gsub('http://','',x)
x = gsub('[^[:graph:]]', ' ',x)
x = gsub('[[:punct:]]', '', x)
x = gsub('[[:cntrl:]]', '', x)
x = gsub('\\d+', '', x)
x = str_replace_all(x,"[^[:graph:]]", " ")
return(x)
}
search_term <- '#inflation'
by <- 'day'
tweets <- search_tweets(q = "#inflation" ,
n = 10000, retryonratelimit = TRUE, lang="en", include_rts = FALSE)
tweets <- tweets %>% as.data.frame()
nrow(tweets)
names(tweets)
tweets[1,]
tweetsSubSet <- tweets %>% select(created_at, text, hashtags)
nrow(tweetsSubSet)
# Ignore graphical Parameters to avoid input errors
tweetsSubSet$text <- str_replace_all(tweetsSubSet$text,"[^[:graph:]]", " ")
tweetsSubSet$text <- cleanText(tweetsSubSet$text)
tweetsSubSet %>% head()
tweetsSubSet <- tweetsSubSet %>%
mutate(Created_At_Round = created_at %>% round(units = 'hours') %>% as.POSIXct())
tweetsSubSet %>% pull(created_at) %>% min()
tweetsSubSet %>% pull(created_at) %>% max()
plt <- tweetsSubSet %>%
count(Created_At_Round) %>%
ggplot(mapping = aes(x = Created_At_Round, y = n)) +
theme_light() +
geom_line() +
xlab(label = 'Date') +
ylab(label = NULL) +
ggtitle(label = 'Number of Tweets per Hour')
plt %>% ggplotly()
### Retrieving positive and negative words
positive <- scan('OpinionLexiconEnglish/positive-words.txt', what = 'character', comment.char = ';')
negative <- scan('OpinionLexiconEnglish/negative-words.txt', what = 'character', comment.char = ';')
# add our list of words below as you wish if missing in above read lists
positiveWords <- c(positive,'upgrade','Congrats','prizes','prize','thanks','thnx',
'Grt','gr8','plz','trending','recovering','brainstorm','leader')
negativeWords <- c(negative,'wtf','wait','waiting','epicfail','Fight','fighting',
'arrest','no','not')
sentimentScore <- function(sentences, pos.words, neg.words){
# require(plyr)
# require(stringr)
# we are giving vector of sentences as input.
# plyr will handle a list or a vector as an "l" for us
# we want a simple array of scores back, so we use "l" + "a" + "ply" = laply:
# sentences = tweetsSubSet$text
# pos.words = positiveWords
# neg.words = negativeWords
scores <- lapply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R's regex-driven global substitute, gsub() function:
sentence <- gsub('https://','',sentence)
sentence <- gsub('http://','',sentence)
sentence <- gsub('[^[:graph:]]', ' ',sentence)
sentence <- gsub('[[:punct:]]', '', sentence)
sentence <- gsub('[[:cntrl:]]', '', sentence)
sentence <- gsub('\\d+', '', sentence)
sentence <- str_replace_all(sentence,"[^[:graph:]]", " ")
# and convert to lower case:
sentence <- tolower(sentence)
# split into words. str_split is in the stringr package
word.list <- str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words <- unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches <- match(words, pos.words)
neg.matches <- match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches <- !is.na(pos.matches)
neg.matches <- !is.na(neg.matches)
# TRUE/FALSE will be treated as 1/0 by sum():
score <- sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words)
scores <- unlist(scores)
sentences <- unlist(sentences)
scores.df <- data.frame(score=scores, text=sentences)
return(scores.df)
}
analysisSentiment <- sentimentScore(sentences = tweetsSubSet$text, pos.words = positiveWords,
neg.words = negativeWords)
analysisSentiment %>%
ggplot(aes(x=score)) +
geom_histogram(binwidth = 1, fill = "lightblue")+
ylab("Frequency") +
xlab("sentiment score") +
ggtitle("Distribution of Sentiment scores of the tweets") +
ggeasy::easy_center_title()
neutral <- length(which(analysisSentiment$score == 0))
positive <- length(which(analysisSentiment$score > 0))
negative <- length(which(analysisSentiment$score < 0))
Sentiment <- c("Positive","Neutral","Negative")
Count <- c(positive,neutral,negative)
output <- data.frame(Sentiment,Count)
output$Sentiment<-factor(output$Sentiment,levels=Sentiment)
ggplot(output, aes(x=Sentiment,y=Count))+
geom_bar(stat = "identity", aes(fill = Sentiment))+
ggtitle("Barplot of Sentiment for inflation")
text_corpus <- Corpus(VectorSource(tweetsSubSet$text))
text_corpus <- tm_map(text_corpus, content_transformer(tolower))
text_corpus <- tm_map(text_corpus, function(x)removeWords(x,stopwords("english")))
text_corpus <- tm_map(text_corpus, removeWords, c("inflation"))
tdm <- TermDocumentMatrix(text_corpus)
tdm <- as.matrix(tdm)
tdm <- sort(rowSums(tdm), decreasing = TRUE)
tdm <- data.frame(word = names(tdm), freq = tdm)
set.seed(123)
wordcloud(text_corpus, min.freq = 1, max.words = 100, scale = c(2.2,1),
colors=brewer.pal(8, "Dark2"), random.color = T, random.order = F)
tweetsSubSet
cloudW <- wordcloud(text_corpus, min.freq = 1, max.words = 100, scale = c(2.2,1),
colors=brewer.pal(8, "Dark2"), random.color = T, random.order = F)
cloudW
ggplot(tdm[1:20,], aes(x=reorder(word, freq), y=freq)) +
geom_bar(stat="identity") +
xlab("Terms") +
ylab("Count") +
coord_flip() +
theme(axis.text=element_text(size=7)) +
ggtitle('Most common word frequency plot') +
ggeasy::easy_center_title()
text_corpus <- tm_map(text_corpus, removeWords, c("inflation", "will", "can"))
tdm <- TermDocumentMatrix(text_corpus)
tdm <- as.matrix(tdm)
tdm <- sort(rowSums(tdm), decreasing = TRUE)
tdm <- data.frame(word = names(tdm), freq = tdm)
set.seed(123)
wordcloud(text_corpus, min.freq = 1, max.words = 100, scale = c(2.2,1),
colors=brewer.pal(8, "Dark2"), random.color = T, random.order = F)
ggplot(tdm[1:20,], aes(x=reorder(word, freq), y=freq)) +
geom_bar(stat="identity") +
xlab("Terms") +
ylab("Count") +
coord_flip() +
theme(axis.text=element_text(size=7)) +
ggtitle('Most common word frequency plot') +
ggeasy::easy_center_title()
#bigram
bi.gram.words <- tweetsSubSet %>%
unnest_tokens(
input = text,
output = bigram,
token = 'ngrams',
n = 2
) %>%
filter(! is.na(bigram))
bi.gram.words %>%
select(bigram) %>%
head(10)
extra.stop.words <- c('https')
stopwords.df <- tibble(
word = c(stopwords(kind = 'es'),
stopwords(kind = 'en'),
extra.stop.words)
)
bi.gram.words %<>%
separate(col = bigram, into = c('word1', 'word2'), sep = ' ') %>%
filter(! word1 %in% stopwords.df$word) %>%
filter(! word2 %in% stopwords.df$word) %>%
filter(! is.na(word1)) %>%
filter(! is.na(word2))
bi.gram.count <- bi.gram.words %>%
dplyr::count(word1, word2, sort = TRUE) %>%
dplyr::rename(weight = n)
bi.gram.count %>% head()
threshold <- 50
# For visualization purposes we scale by a global factor.
ScaleWeight <- function(x, lambda) {
x / lambda
}
network <-  bi.gram.count %>%
filter(weight > threshold) %>%
mutate(weight = ScaleWeight(x = weight, lambda = 2E3)) %>%
graph_from_data_frame(directed = FALSE)
plot(
network,
vertex.size = 1,
vertex.label.color = 'black',
vertex.label.cex = 0.7,
vertex.label.dist = 1,
edge.color = 'gray',
main = 'Bigram Count Network',
sub = glue('Weight Threshold: {threshold}'),
alpha = 50
)
V(network)$degree <- strength(graph = network)
# Compute the weight shares.
E(network)$width <- E(network)$weight/max(E(network)$weight)
plot(
network,
vertex.color = 'lightblue',
# Scale node size by degree.
vertex.size = 2*V(network)$degree,
vertex.label.color = 'black',
vertex.label.cex = 0.6,
vertex.label.dist = 1.6,
edge.color = 'gray',
# Set edge width proportional to the weight relative value.
edge.width = 3*E(network)$width ,
main = 'Bigram Count Network',
sub = glue('Weight Threshold: {threshold}'),
alpha = 50
)
threshold <- 50
network <-  bi.gram.count %>%
filter(weight > threshold) %>%
graph_from_data_frame(directed = FALSE)
# Store the degree.
V(network)$degree <- strength(graph = network)
# Compute the weight shares.
E(network)$width <- E(network)$weight/max(E(network)$weight)
# Create networkD3 object.
network.D3 <- igraph_to_networkD3(g = network)
# Define node size.
network.D3$nodes %<>% mutate(Degree = (1E-2)*V(network)$degree)
# Define color group
network.D3$nodes %<>% mutate(Group = 1)
# Define node size.
network.D3$nodes %>% mutate(Degree = (1E-2)*V(network)$degree)
# Define color group
network.D3$nodes %>% mutate(Group = 1)
# Define edges width.
network.D3$links$Width <- 10*E(network)$width
forceNetwork(
Links = network.D3$links,
Nodes = network.D3$nodes,
Source = 'source',
Target = 'target',
NodeID = 'name',
Group = 'Group',
opacity = 0.9,
Value = 'Width',
Nodesize = 'Degree',
# We input a JavaScript function.
linkWidth = JS("function(d) { return Math.sqrt(d.value); }"),
fontSize = 12,
zoom = TRUE,
opacityNoHover = 1
)
network.D3
forceNetwork(
Links = network.D3$links,
Nodes = network.D3$nodes,
Source = 'source',
Target = 'target',
NodeID = 'name',
Group = 'Group',
opacity = 0.9,
Value = 'Width',
Nodesize = 'Degree',
# We input a JavaScript function.
linkWidth = JS("function(d) { return Math.sqrt(d.value); }"),
fontSize = 12,
zoom = TRUE,
opacityNoHover = 1
)
forceNetwork(
Links = network.D3$links,
Nodes = network.D3$nodes,
Source = 'source',
Target = 'target',
NodeID = 'name',
opacity = 0.9,
Value = 'Width',
Nodesize = 'Degree',
# We input a JavaScript function.
linkWidth = JS("function(d) { return Math.sqrt(d.value); }"),
fontSize = 12,
zoom = TRUE,
opacityNoHover = 1
)
forceNetwork(
Links = network.D3$links,
Nodes = network.D3$nodes,
Source = 'source',
Target = 'target',
NodeID = 'name',
opacity = 0.9,
Value = 'Width',
# We input a JavaScript function.
linkWidth = JS("function(d) { return Math.sqrt(d.value); }"),
fontSize = 12,
zoom = TRUE,
opacityNoHover = 1
)
librarian::shelf(tidyverse, reshape2, readxl, data.table, nleqslv, BB, Metrics, ggthemes, pracma,
twitteR, ROAuth, hms, lubridate, tidytext, tm, wordcloud, igraph, glue, networkD3,
rtweet, stringr, ggeasy, plotly, janeaustenr, widyr, textdata)
tweets
text_corpus
install.packages("tm")
librarian::shelf(tm, SnowballC, wordcloud, readtext)
wordbase <- readtext("DineshPoddaturi-ProposalPacket.pdf")
librarian::shelf(tm, SnowballC, wordcloud, readtext, pdftools)
install.packages("pdftools")
librarian::shelf(tm, SnowballC, wordcloud, readtext, pdftools)
library(pdftools)
readtext("DineshPoddaturi-ProposalPacket.pdf")
pdf_text("DineshPoddaturi-ProposalPacket.pdf")
remove.packages("pdftools")
install.packages("pdftools")
library(pdftools)
pdftools::pdf_text("DineshPoddaturi-ProposalPacket.pdf")
install.packages("pdftools")
install.packages("wordcloud")
install.packages("wordcloud")
.libPaths()
